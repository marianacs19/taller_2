precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
reducted_tree <- rpart(formula = Pobre~Espacios_hogar+Propiedad_vivienda+arriendo_compilado_hogar+Ayudas_gobierno_12m_jefe + Oficio_C8_jefe,
data = train_def,
method = "class",
minbucket = 200,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
reducted_tree <- rpart(formula = Pobre~Espacios_hogar+Propiedad_vivienda+arriendo_compilado_hogar+Ayudas_gobierno_12m_jefe + Oficio_C8_jefe,
data = train_def,
method = "class",
minbucket = 1000,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
basic_tree <- rpart(formula = Pobre~Espacios_hogar+Propiedad_vivienda+arriendo_compilado_hogar+Ayudas_gobierno_12m_jefe + Oficio_C8_jefe,
data = train_def,
method = "class",
cp = 0)
rpart.plot::prp(
basic_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_basic <- predict(basic_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
# Reducted tree (observations)
reducted_tree <- rpart(formula = Pobre~Espacios_hogar+Propiedad_vivienda+arriendo_compilado_hogar+Ayudas_gobierno_12m_jefe + Oficio_C8_jefe,
data = train_def,
method = "class",
minbucket = 1000,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar +
Afiliados_salud_hogar,,
data = train_def,
method = "class",
cp = 0)
rpart.plot::prp(
basic_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar +
Afiliados_salud_hogar,,
data = train_def,
method = "class",
cp = 0)
#rpart.plot::prp(
#  basic_tree,
#  under = TRUE,      # Mostrar la información debajo de cada nodo
#  branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
#  yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
#  faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
#  varlen = 15,       # Longitud máxima para abreviar los nombres de variables
#  box.palette = "-RdYlGn"  # Paleta de colores para las hojas
#)
pred_basic <- predict(basic_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
reducted_tree <- rpart(Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 1000,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
reducted_tree <- rpart(Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 1000,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
reducted_tree <- rpart(Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 200,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda +
Afiliados_salud_hogar + P,
data = train_def,
method = "class",
cp = 0)
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda +
Afiliados_salud_hogar,
data = train_def,
method = "class",
cp = 0)
#rpart.plot::prp(
#  basic_tree,
#  under = TRUE,      # Mostrar la información debajo de cada nodo
#  branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
#  yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
#  faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
#  varlen = 15,       # Longitud máxima para abreviar los nombres de variables
#  box.palette = "-RdYlGn"  # Paleta de colores para las hojas
#)
pred_basic <- predict(basic_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
cp = 0)
#rpart.plot::prp(
#  basic_tree,
#  under = TRUE,      # Mostrar la información debajo de cada nodo
#  branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
#  yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
#  faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
#  varlen = 15,       # Longitud máxima para abreviar los nombres de variables
#  box.palette = "-RdYlGn"  # Paleta de colores para las hojas
#)
pred_basic <- predict(basic_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
reducted_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 200,
cp = 0)
pred_reducted <- predict(reducted_tree, newdata = train_def, type = "class")
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
probs_basic  <- predict(basic_tree, newdata = train_def, type = "prob")
probs_basic_pobre <- probs_basic[, "Pobre"]
# Apply your cutoff
cutoff <- 0.3
pred_basic_custom <- ifelse(probs_basic_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
cp = 0)
#rpart.plot::prp(
#  basic_tree,
#  under = TRUE,      # Mostrar la información debajo de cada nodo
#  branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
#  yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
#  faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
#  varlen = 15,       # Longitud máxima para abreviar los nombres de variables
#  box.palette = "-RdYlGn"  # Paleta de colores para las hojas
#)
probs_basic  <- predict(basic_tree, newdata = train_def, type = "prob")
probs_basic_pobre <- probs_basic[, "Pobre"]
# Apply your cutoff
cutoff <- 0.3
pred_basic_custom <- ifelse(probs_basic_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
cm_basic <- confusionMatrix(pred_basic, train_def$pred_basic_custom, positive = "Pobre")
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic_custom, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
reducted_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 200,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_basic[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_basic <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_basic
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
cutoff <- 0.5
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_basic[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_basic <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_basic
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
cutoff <- 0.5
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_basic[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
cutoff <- 0.3
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_basic[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
rm(list = ls())
#Modelos con  Forest:
library(pacman)
p_load(rio,           # import/export data
tidyverse,     # tidy-data
glmnet,        # To implement regularization algorithms.
rpart,         # To implement decision trees.
rpart.plot,    # To plot trees.
caret,         # To estimate predictive models.
Metrics        # To evaluate predictive models.
)
load("~/GitHub/taller_2/Data/test_def.RData")
load("~/GitHub/taller_2/Data/train_def.RData")
train_def <- train_def %>%
mutate(arriendo_compilado_hogar = coalesce(Arriendo_estimado_mensual, Arriendo_pagado_mensual))
test_def <- train_def %>%
mutate(arriendo_compilado_hogar = coalesce(Arriendo_estimado_mensual, Arriendo_pagado_mensual))
#  Forest
#Basic Tree
basic_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
cp = 0)
#rpart.plot::prp(
#  basic_tree,
#  under = TRUE,      # Mostrar la información debajo de cada nodo
#  branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
#  yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
#  faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
#  varlen = 15,       # Longitud máxima para abreviar los nombres de variables
#  box.palette = "-RdYlGn"  # Paleta de colores para las hojas
#)
probs_basic  <- predict(basic_tree, newdata = train_def, type = "prob")
probs_basic_pobre <- probs_basic[, "Pobre"]
# Apply your cutoff
cutoff <- 0.3
pred_basic_custom <- ifelse(probs_basic_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_basic <- confusionMatrix(pred_basic_custom, train_def$Pobre, positive = "Pobre")
cm_basic
# Extract F1 manually
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
# Reducted tree (observations)
reducted_tree <- rpart(formula = Pobre ~ `Años_educ_mean_hogar` +
Asalariados_hogar  + arriendo_compilado_hogar + Propiedad_vivienda + Oficio_C8_jefe +
Afiliados_salud_hogar,
data = train_def,
method = "class",
minbucket = 200,
cp = 0)
prp(reducted_tree)
rpart.plot::prp(
reducted_tree,
under = TRUE,      # Mostrar la información debajo de cada nodo
branch.lty = 2,    # Tipo de línea para las ramas (2 = línea punteada)
yesno = 1,         # Mostrar indicadores de "sí"/"no" solo en el primer nodo.
faclen = 0,        # Longitud de la abreviación para niveles de factores (0 = sin abreviación)
varlen = 15,       # Longitud máxima para abreviar los nombres de variables
box.palette = "-RdYlGn"  # Paleta de colores para las hojas
)
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_basic[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
precision_basic <- cm_basic$byClass["Precision"]
recall_basic    <- cm_basic$byClass["Recall"]
F1_basic <- 2 * ((precision_basic * recall_basic) / (precision_basic + recall_basic))
F1_basic
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
cm_basic <- confusionMatrix(pred_basic_custom, train_def$Pobre, positive = "Pobre")
cm_basic
probs_reducted <- predict(reducted_tree, newdata = train_def, type = "prob")
probs_reducted_pobre <- probs_reducted[, "Pobre"]
pred_reducted_custom <- ifelse(probs_reducted_pobre >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
# Confusion matrix
cm_reducted <- confusionMatrix(pred_reducted_custom, train_def$Pobre, positive = "Pobre")
cm_reducted
# Extract F1 manually
precision_reducted <- cm_reducted$byClass["Precision"]
recall_reducted    <- cm_reducted$byClass["Recall"]
F1_reducted <- 2 * ((precision_reducted * recall_reducted) / (precision_reducted + recall_reducted))
F1_reducted
get_f1 <- function(model, data, cutoff = 0.5) {
probs <- predict(model, newdata = data, type = "prob")[, "Pobre"]
preds <- ifelse(probs >= cutoff, "Pobre", "No_pobre") %>% factor(levels = c("No_pobre", "Pobre"))
cm <- confusionMatrix(preds, data$Pobre, positive = "Pobre")
P <- cm$byClass["Precision"]
R <- cm$byClass["Recall"]
F1 <- 2 * ((P * R) / (P + R))
return(round(F1, 3))
}
# Example:
get_f1(basic_tree, train_def, cutoff = 0.3)
get_f1(basic_tree, train_def, cutoff = 0.5)
get_f1(basic_tree, train_def, cutoff = 0.7)
